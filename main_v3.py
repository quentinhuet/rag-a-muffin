import os 
import sys
from src.data_loader import load_data
from src.embeddings import RAGTool
from src.vector_store import RecipeDB
from src.generator_v2 import MuffinChef

current_file_path = os.path.abspath(__file__)
project_root = os.path.dirname(current_file_path)
data_path = os.path.join(project_root, 'data', 'raw', 'recettes_fr.json')

tool = RAGTool()
database = RecipeDB()

# Initialisation de la base de donnÃ©es, si ce n'est pas dÃ©jÃ  fait.
if database.collection.count() == 0:
    data = load_data(data_path)
    textes = []
    for recette in data:
        textes.append((recette['texte']))
    
    embeddings = tool.vectoriser(data = textes)
    database.add_recipes(data = data, embeddings=embeddings)

print("âœ… Base de donnÃ©es prÃªte !")

# Discussion avec l'utilisateur

#Initialisation du LLM : 
chef = MuffinChef()

recette_active = None

while True:
    question = input("\n ğŸ§‘â€ğŸ³ CHEF MUFFIN : Pose moi la question que tu veux sur la recette en cours. \n Si tu souhaites changer de recette, entre 'changer' \n " if recette_active else "\n ğŸ§‘â€ğŸ³ CHEF MUFFIN : Bonjour ! Je suis Chef Muffin. \n Je vais t'aider Ã  prÃ©parer de dÃ©licieux muffins. \n Donne moi les ingrÃ©dients que tu as Ã  disposition, ou le type de muffins que tu souhaiterais faire. \n Sinon, entre 'exit' pour quitter. \n Votre rÃ©ponse :")
    #Pour s'assurer, lors de la premiÃ¨re demande de l'utilisateur, que tous les Ã©lÃ©ments clÃ©s lui sont donnÃ©s
    
    if question.lower() in ["exit", "q", "quit"]:
            print("ğŸ§‘â€ğŸ³ CHEF MUFFIN : Bon appÃ©tit et Ã  bientÃ´t ! ğŸ‘‹")
            break
    
    # --- MÃ‰CANIQUE DE RESET ---
    mots_cles_changement = ["changer", "autre recette", "nouvelle recherche", "nouveau"]
    if any(mot in question.lower() for mot in mots_cles_changement):
        print("ğŸ§‘â€ğŸ³ CHEF MUFFIN : ğŸ”„ D'accord, changeons de recette !")
        recette_active = None
        chef.reset_memory() # On vide la mÃ©moire du chef
        continue

    # --- CAS 1 : MODE RECHERCHE (Pas de recette active) ---
    if recette_active is None:
        vecteur_question = tool.vectoriser([question])[0].tolist()
        reponse = database.search(query_embedding=vecteur_question, k=1)
        
        if reponse['documents']:
            # On a trouvÃ© ! On "verrouille" cette recette
            recette_active = reponse['documents'][0][0] # Le texte de la recette
            titre = reponse['metadatas'][0][0]['titre']
            
            # On laisse le code continuer vers le LLM 
        else:
            print("ğŸ§‘â€ğŸ³ CHEF MUFFIN : DÃ©solÃ©, je n'ai aucune recette qui correspond. Essaie autre chose.")
            continue

    # --- CAS 2 : MODE DISCUSSION (Recette active) ---
    
    reponse_llm = chef.generate_response(context_str=recette_active, query_str=question)
    
    print("\n" + "-"*50)
    print(f"ğŸ§‘â€ğŸ³ CHEF MUFFIN : {reponse_llm}")
    print("-"*50)